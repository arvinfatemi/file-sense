# AI File Concierge (AFC)

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**An intelligent agentic system for semantic file organization and search**

AI File Concierge is a capstone project for the [Kaggle 5-Day GenAI Agents Intensive](https://www.kaggle.com/learn-guide/5-day-agents) that demonstrates how agent-based reasoning, tools, and memory enable smarter file organization through natural language interaction.

## Features

âœ¨ **Natural Language Search** - Find files using semantic queries instead of exact filenames
ğŸ·ï¸ **Smart Tagging** - AI-powered tag suggestions for automatic file organization
ğŸ“ **Virtual Collections** - Create dynamic file collections based on search results or tags
ğŸ¤– **Agentic Architecture** - Multi-agent system using Google ADK and Gemini
ğŸ’¾ **Persistent Memory** - Short-term (session) and long-term (database) memory systems
ğŸ” **Vector Search** - Semantic search powered by sentence transformers and ChromaDB

## Quick Start

### Prerequisites

- Python 3.8 or higher
- Google API key for Gemini ([Get one here](https://makersuite.google.com/app/apikey))

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/file-sense.git
cd file-sense
```

2. **Create a virtual environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Set up environment variables**
```bash
cp .env.example .env
# Edit .env and add your GOOGLE_API_KEY
```

5. **Index the sandbox files**
```bash
python main.py index
```

6. **Start the interactive CLI**
```bash
python main.py interactive
```

## Usage Examples

### Interactive Mode

```bash
$ python main.py interactive

You: Find my Python files

Agent: I found 2 Python files in your sandbox:
1. code/ml_experiment.py - Bayesian A/B testing implementation
2. code/data_processing.py - ETL utilities with pandas

You: Create a collection for all machine learning related files

Agent: I've created a collection called "Machine Learning" with 1 file:
- code/ml_experiment.py

You: Suggest tags for documents/resume.txt

Agent: I suggest the following tags for documents/resume.txt:
- career
- resume
- software-engineering
- job-search

Would you like me to apply these tags?
```

### Command-Line Interface

```bash
# Index all files
python main.py index

# Search files
python main.py search "machine learning notes"

# View statistics
python main.py stats
```

### Example Queries

- `"Find my Bayesian A/B testing notes"`
- `"Show everything related to job applications"`
- `"Search for documents about transformers and attention"`
- `"Create a collection for all Python code files"`
- `"What files do I have about machine learning?"`

## Project Structure

```
file-sense/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/           # Agent architecture
â”‚   â”‚   â”œâ”€â”€ orchestrator.py    # Main orchestrator agent
â”‚   â”‚   â””â”€â”€ file_concierge.py  # System coordinator
â”‚   â”œâ”€â”€ tools/            # Agent tools
â”‚   â”‚   â”œâ”€â”€ file_tools.py       # File operations
â”‚   â”‚   â”œâ”€â”€ search_tools.py     # Semantic search
â”‚   â”‚   â”œâ”€â”€ tag_tools.py        # Tagging operations
â”‚   â”‚   â””â”€â”€ collection_tools.py # Collection management
â”‚   â”œâ”€â”€ memory/           # Memory systems
â”‚   â”‚   â”œâ”€â”€ short_term.py       # Session memory
â”‚   â”‚   â””â”€â”€ long_term.py        # Persistent storage
â”‚   â”œâ”€â”€ indexing/         # File processing
â”‚   â”‚   â”œâ”€â”€ file_processor.py   # Metadata extraction
â”‚   â”‚   â””â”€â”€ vector_store.py     # Vector embeddings
â”‚   â””â”€â”€ ui/               # User interface
â”‚       â””â”€â”€ cli.py              # Command-line interface
â”œâ”€â”€ sandbox/              # Sandboxed file directory
â”‚   â”œâ”€â”€ documents/        # Sample documents
â”‚   â”œâ”€â”€ code/            # Sample code files
â”‚   â”œâ”€â”€ notes/           # Sample notes
â”‚   â””â”€â”€ misc/            # Miscellaneous files
â”œâ”€â”€ config/              # Configuration
â”œâ”€â”€ evaluation/          # Evaluation scripts
â”œâ”€â”€ tests/              # Unit tests
â”œâ”€â”€ main.py             # Entry point
â”œâ”€â”€ requirements.txt    # Python dependencies
â””â”€â”€ README.md          # This file
```

## Architecture

### Agentic System

The system uses a multi-agent architecture with the **Orchestrator Agent** coordinating multiple specialized tools:

```
User Query â†’ Orchestrator Agent â†’ Tools (File, Search, Tag, Collection)
                â†“
          Short-term Memory (Conversation context)
                â†“
          Long-term Memory (SQLite + ChromaDB)
                â†“
          Sandbox Filesystem
```

### Tools

1. **File Tools** - Read, list, and extract metadata from files
2. **Search Tools** - Semantic search using vector embeddings
3. **Tag Tools** - AI-powered tag suggestion and management
4. **Collection Tools** - Create and manage file collections

### Memory

- **Short-term Memory**: Tracks conversation history and current session context
- **Long-term Memory**: Persists file metadata, tags, collections, and embeddings in SQLite and ChromaDB

## Evaluation

Run the evaluation suite to test system performance:

```bash
python evaluation/test_scenarios.py
```

The evaluation tests:
- **Search Accuracy** (Hit@K metrics)
- **Tag Quality** (Relevance scoring)
- **Workflow Scenarios** (End-to-end operations)

See [evaluation/README.md](evaluation/README.md) for details.

<!-- ## Capstone Requirements

This project fulfills all capstone requirements:

âœ… **Agentic Architecture** - Orchestrator agent with tool-based workflow
âœ… **Tools** - 7+ specialized tools for file operations
âœ… **Memory** - Short-term (session) and long-term (database) storage
âœ… **Evaluation** - Automated test scenarios with metrics
âœ… **Production Thinking** - See [PRODUCTION_SCALING.md](PRODUCTION_SCALING.md)
âœ… **Public Repository** - Clean code, documentation, and examples -->

<!-- ## Production Scaling

For a detailed discussion of how to scale this prototype to production, see [PRODUCTION_SCALING.md](PRODUCTION_SCALING.md), which covers:

- Real filesystem integration via MCP
- Distributed vector databases (Pinecone, Weaviate)
- Cloud storage integration (Google Drive, Dropbox, etc.)
- Multimodal support (OCR, audio transcription, video)
- Security and privacy considerations
- Cost optimization strategies -->

## Technology Stack

- **Agent Framework**: Google ADK with Gemini
- **LLM**: Gemini 2.0 Flash
- **Embeddings**: Sentence Transformers (all-MiniLM-L6-v2)
- **Vector Store**: ChromaDB
- **Database**: SQLite
- **CLI**: Rich, Click
- **Language**: Python 3.8+

<!-- ## Limitations

This is a **prototype** with the following limitations:

- Operates only on a sandboxed directory (not real filesystem)
- Single-user, local-only (no multi-user support)
- No authentication or authorization
- Limited file type support (text files primarily)
- No cloud storage integration
- SQLite database (not production-scale)

See [PRODUCTION_SCALING.md](PRODUCTION_SCALING.md) for how to address these. -->

## Contributing

This is a capstone project, but suggestions and feedback are welcome! Please open an issue to discuss proposed changes.

## License

MIT License - see [LICENSE](LICENSE) for details.

<!-- ## Acknowledgments

- [Kaggle 5-Day GenAI Agents Intensive](https://www.kaggle.com/learn-guide/5-day-agents) for project inspiration
- [Google ADK](https://google.github.io/adk-docs/) for the agent framework
- Course instructors and community for guidance -->

## References

- [Capstone Project Details](https://www.kaggle.com/competitions/agents-intensive-capstone-project)
- [Google ADK Documentation](https://google.github.io/adk-docs/)
- [Project Brief](STARTER.md)

---

**Built with â¤ï¸ for the Kaggle GenAI Agents Intensive**
